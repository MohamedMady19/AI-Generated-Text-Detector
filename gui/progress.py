"""
Enhanced progress tracking component for the GUI.
ðŸš€ COMPLETELY FIXED VERSION with smooth real-time paragraph-level progress tracking
âœ… FIXES: Eliminated 0% â†’ 100% jumps, real-time updates, better performance metrics
"""

import time
import logging
from typing import Optional, Callable, Dict, Any
from dataclasses import dataclass
from enum import Enum
import threading

logger = logging.getLogger(__name__)


class ProcessingStatus(Enum):
    """Enumeration of processing statuses."""
    IDLE = "idle"
    STARTING = "starting"
    PROCESSING = "processing"
    COMPLETED = "completed"
    ERROR = "error"
    CANCELLED = "cancelled"


@dataclass
class ProgressUpdate:
    """Data class for progress updates."""
    current: int
    total: int
    percentage: float
    message: str
    timestamp: float
    status: ProcessingStatus
    details: Optional[Dict[str, Any]] = None


class EnhancedProgressTracker:
    """ðŸš€ COMPLETELY FIXED: Enhanced progress tracker with REAL-TIME granular updates."""
    
    def __init__(self):
        self.reset()
        self._lock = threading.Lock()  # Thread safety
    
    def reset(self):
        """Reset all progress tracking."""
        with getattr(self, '_lock', threading.Lock()):
            self._current_file = 0
            self._total_files = 0
            self._current_step = 0
            self._total_steps = 0
            self._overall_progress = 0.0
            self._status = ProcessingStatus.IDLE
            self._current_message = "Ready"
            self._start_time = None
            self._end_time = None
            self._file_progress = {}
            self._file_paragraph_counts = {}
            self._file_paragraph_progress = {}
            self._step_weights = {}
            self._callbacks = []
            self._error_message = None
            
            # ðŸš€ CRITICAL FIX: Enhanced tracking for REAL-TIME updates
            self._processing_stage = "Ready"
            self._current_file_name = ""
            self._paragraphs_processed = 0
            self._total_paragraphs = 0
            self._features_extracted = 0
            self._processing_speed = 0.0
            self._performance_metrics = {}
            self._stage_start_times = {}
            
            # ðŸš€ PERFORMANCE: More granular step tracking
            self._last_update_time = 0
            self._update_frequency = 0.05  # Update every 50ms for smooth progress
            
            logger.debug("ðŸš€ FIXED: Enhanced progress tracker reset")
    
    def add_callback(self, callback: Callable[[ProgressUpdate], None]):
        """Add a progress update callback."""
        with self._lock:
            if callback not in self._callbacks:
                self._callbacks.append(callback)
                logger.debug("Added progress callback")
    
    def remove_callback(self, callback: Callable[[ProgressUpdate], None]):
        """Remove a progress update callback."""
        with self._lock:
            if callback in self._callbacks:
                self._callbacks.remove(callback)
                logger.debug("Removed progress callback")
    
    def start_processing(self, total_files: int, file_names: list = None):
        """
        ðŸš€ FIXED: Start a new processing operation with enhanced tracking.
        
        Args:
            total_files: Total number of files to process
            file_names: Optional list of file names
        """
        with self._lock:
            self.reset()
            self._total_files = total_files
            self._start_time = time.time()
            self._status = ProcessingStatus.STARTING
            self._processing_stage = "Initializing"
            
            # Initialize file progress tracking
            if file_names:
                for name in file_names:
                    self._file_progress[name] = 0
                    self._file_paragraph_counts[name] = 0
                    self._file_paragraph_progress[name] = 0
            
            # ðŸš€ CRITICAL FIX: More granular step weights for smoother progress
            self._step_weights = {
                'reading': 0.08,           # Reading files from disk (8%)
                'parsing': 0.07,           # Parsing file content (7%)
                'filtering': 0.05,         # Content filtering and validation (5%)
                'spacy_processing': 0.15,  # spaCy NLP processing (15%)
                'feature_extraction': 0.60, # Main feature extraction (60%)
                'saving': 0.05             # Saving results to CSV (5%)
            }
        
        self._notify_callbacks("ðŸš€ Starting FIXED enhanced processing...")
        logger.info(f"ðŸš€ FIXED: Started enhanced processing of {total_files} files")
    
    def start_stage(self, stage_name: str):
        """Start a new processing stage."""
        with self._lock:
            self._processing_stage = stage_name
            self._stage_start_times[stage_name] = time.time()
        logger.debug(f"Started processing stage: {stage_name}")
    
    def end_stage(self, stage_name: str):
        """End a processing stage and calculate metrics."""
        with self._lock:
            if stage_name in self._stage_start_times:
                duration = time.time() - self._stage_start_times[stage_name]
                self._performance_metrics[f"{stage_name}_duration"] = duration
                logger.debug(f"Completed stage {stage_name} in {duration:.2f}s")
    
    def set_file_paragraph_count(self, file_index: int, file_name: str, paragraph_count: int):
        """
        ðŸš€ FIXED: Set the total paragraph count for a file with enhanced tracking.
        
        Args:
            file_index: Index of the file
            file_name: Name of the file
            paragraph_count: Total number of paragraphs in the file
        """
        with self._lock:
            self._file_paragraph_counts[file_name] = paragraph_count
            self._file_paragraph_progress[file_name] = 0
            self._total_paragraphs = sum(self._file_paragraph_counts.values())
        
        logger.debug(f"Set paragraph count for {file_name}: {paragraph_count} (total: {self._total_paragraphs})")
    
    def update_paragraph_progress(self, file_index: int, file_name: str, 
                                 paragraphs_processed: int, total_paragraphs: int):
        """
        ðŸš€ CRITICAL FIX: Update paragraph processing progress with REAL-TIME granular updates.
        
        Args:
            file_index: Index of current file
            file_name: Name of current file
            paragraphs_processed: Number of paragraphs processed so far
            total_paragraphs: Total paragraphs in the file
        """
        if self._status == ProcessingStatus.CANCELLED:
            return
        
        current_time = time.time()
        
        # ðŸš€ CRITICAL FIX: Much more frequent updates (every 50ms instead of throttling)
        should_update = (
            current_time - self._last_update_time > self._update_frequency or
            paragraphs_processed == total_paragraphs or  # Always update on completion
            paragraphs_processed % 2 == 0  # Update every 2 paragraphs instead of 10
        )
        
        if not should_update:
            return
        
        with self._lock:
            # Update paragraph progress
            old_progress = self._file_paragraph_progress.get(file_name, 0)
            self._file_paragraph_progress[file_name] = paragraphs_processed
            self._file_paragraph_counts[file_name] = total_paragraphs
            self._current_file_name = file_name
            
            # Update global counters
            self._paragraphs_processed = sum(self._file_paragraph_progress.values())
            self._total_paragraphs = sum(self._file_paragraph_counts.values())
            
            # Calculate processing speed
            if self._start_time:
                elapsed = current_time - self._start_time
                if elapsed > 0:
                    self._processing_speed = self._paragraphs_processed / elapsed
            
            # Calculate progress within current stage
            if total_paragraphs > 0:
                paragraph_progress = paragraphs_processed / total_paragraphs
            else:
                paragraph_progress = 1.0
            
            # ðŸš€ CRITICAL FIX: Update the feature extraction step progress with better calculation
            self.update_file_progress(file_index, file_name, 'feature_extraction', paragraph_progress)
        
        # Update last update time
        self._last_update_time = current_time
        
        # ðŸš€ CRITICAL FIX: Enhanced message with real-time metrics
        elapsed_time = current_time - self._start_time if self._start_time else 0
        speed_info = f" ({self._processing_speed:.1f} para/sec)" if self._processing_speed > 0 else ""
        
        message = f"ðŸš€ Processing {file_name}: {paragraphs_processed}/{total_paragraphs} paragraphs{speed_info}"
        
        with self._lock:
            self._current_message = message
        
        self._notify_callbacks(message)
        
        logger.debug(f"ðŸš€ FIXED Paragraph progress: {file_name} - {paragraphs_processed}/{total_paragraphs}")
    
    def update_file_progress(self, file_index: int, file_name: str, 
                           step: str, step_progress: float = 1.0):
        """
        ðŸš€ FIXED: Update progress for a specific file and step with enhanced granular tracking.
        
        Args:
            file_index: Index of current file (0-based)
            file_name: Name of current file
            step: Current processing step
            step_progress: Progress within the step (0.0 to 1.0)
        """
        if self._status == ProcessingStatus.CANCELLED:
            return
        
        with self._lock:
            self._current_file = file_index
            self._status = ProcessingStatus.PROCESSING
            self._processing_stage = step
            
            # ðŸš€ CRITICAL FIX: Better step progress calculation
            step_weight = self._step_weights.get(step, 0.1)  # Default 10% if unknown
            completed_steps_weight = sum(
                weight for s, weight in self._step_weights.items() 
                if list(self._step_weights.keys()).index(s) < list(self._step_weights.keys()).index(step)
            ) if step in self._step_weights else 0.0
            
            file_progress = completed_steps_weight + (step_weight * step_progress)
            file_progress = min(file_progress, 1.0)
            
            # Update file progress tracking
            self._file_progress[file_name] = file_progress * 100
            
            # ðŸš€ CRITICAL FIX: Much better overall progress calculation
            if self._total_files > 0:
                completed_files_progress = file_index / self._total_files
                current_file_progress = (file_progress / self._total_files)
                self._overall_progress = (completed_files_progress + current_file_progress) * 100
                
                # Ensure progress never goes backwards
                self._overall_progress = max(self._overall_progress, getattr(self, '_last_overall_progress', 0))
                self._last_overall_progress = self._overall_progress
        
        # ðŸš€ CRITICAL FIX: Create enhanced message (avoid duplication with paragraph progress messages)
        if step != 'feature_extraction':  # Paragraph progress handles feature extraction step messages
            stage_display_names = {
                'reading': 'ðŸ“‚ Reading file',
                'parsing': 'ðŸ“ Parsing content',
                'filtering': 'ðŸ” Filtering content',
                'spacy_processing': 'ðŸ§  NLP processing',
                'saving': 'ðŸ’¾ Saving results'
            }
            display_name = stage_display_names.get(step, f"ðŸ”„ {step}")
            message = f"{display_name}: {file_name}"
            
            with self._lock:
                self._current_message = message
            
            self._notify_callbacks(message)
        
        logger.debug(f"ðŸš€ FIXED File progress: {file_name} - {step} - {file_progress:.1%}")
    
    def update_features_extracted(self, features_count: int):
        """Update the count of features extracted."""
        with self._lock:
            self._features_extracted = features_count
    
    def complete_file(self, file_index: int, file_name: str, paragraphs_extracted: int = 0):
        """
        ðŸš€ FIXED: Mark a file as completed with enhanced metrics and progress updates.
        
        Args:
            file_index: Index of completed file
            file_name: Name of completed file
            paragraphs_extracted: Number of paragraphs extracted
        """
        with self._lock:
            self._file_progress[file_name] = 100
            
            # Update final paragraph count if provided
            if paragraphs_extracted > 0:
                self._file_paragraph_progress[file_name] = paragraphs_extracted
                if file_name not in self._file_paragraph_counts or self._file_paragraph_counts[file_name] == 0:
                    self._file_paragraph_counts[file_name] = paragraphs_extracted
            
            # ðŸš€ CRITICAL FIX: Better overall progress calculation for completed files
            if self._total_files > 0:
                completed_files = file_index + 1
                self._overall_progress = (completed_files / self._total_files) * 100
        
        # Calculate completion metrics
        elapsed_time = time.time() - self._start_time if self._start_time else 0
        files_completed = file_index + 1
        
        message = f"âœ… Completed {file_name}"
        if paragraphs_extracted > 0:
            message += f": {paragraphs_extracted} paragraphs"
        if elapsed_time > 0:
            files_per_sec = files_completed / elapsed_time
            message += f" ({files_per_sec:.1f} files/sec)"
        
        with self._lock:
            self._current_message = message
        
        self._notify_callbacks(message)
        
        logger.info(f"âœ… Completed file: {file_name} ({paragraphs_extracted} paragraphs)")
    
    def complete_processing(self, total_paragraphs: int = 0, processed_files: int = None):
        """
        ðŸš€ FIXED: Mark processing as completed with comprehensive metrics.
        
        Args:
            total_paragraphs: Total paragraphs processed
            processed_files: Number of successfully processed files
        """
        with self._lock:
            self._status = ProcessingStatus.COMPLETED
            self._overall_progress = 100.0
            self._end_time = time.time()
            
            if processed_files is None:
                processed_files = self._total_files
        
        duration = self._end_time - self._start_time if self._start_time else 0
        
        # Calculate comprehensive metrics
        files_per_sec = processed_files / duration if duration > 0 else 0
        paragraphs_per_sec = total_paragraphs / duration if duration > 0 else 0
        
        message = f"âœ… FIXED: Completed! {total_paragraphs} paragraphs from {processed_files} files"
        if duration > 0:
            message += f" in {self._format_duration(duration)}"
            message += f" ({files_per_sec:.1f} files/sec, {paragraphs_per_sec:.1f} para/sec)"
        
        with self._lock:
            self._current_message = message
        
        self._notify_callbacks(message)
        
        logger.info(f"ðŸš€ FIXED Enhanced processing completed: {processed_files}/{self._total_files} files, "
                   f"{total_paragraphs} paragraphs, {duration:.1f}s")
    
    def error_processing(self, error_message: str, file_name: str = None):
        """
        Mark processing as failed with an error.
        
        Args:
            error_message: Error description
            file_name: Optional file name where error occurred
        """
        with self._lock:
            self._status = ProcessingStatus.ERROR
            self._error_message = error_message
            self._end_time = time.time()
        
        message = f"âŒ Error: {error_message}"
        if file_name:
            message = f"âŒ Error in {file_name}: {error_message}"
        
        with self._lock:
            self._current_message = message
        
        self._notify_callbacks(message)
        
        logger.error(f"Processing error: {error_message}" + (f" (file: {file_name})" if file_name else ""))
    
    def cancel_processing(self):
        """Cancel the current processing operation."""
        with self._lock:
            self._status = ProcessingStatus.CANCELLED
            self._end_time = time.time()
            self._current_message = "âŒ Processing cancelled"
        
        self._notify_callbacks("Processing cancelled")
        logger.info("ðŸ›‘ Processing cancelled by user")
    
    def get_real_time_metrics(self) -> Dict[str, Any]:
        """ðŸš€ FIXED: Get real-time processing metrics with enhanced data."""
        with self._lock:
            elapsed = self.elapsed_time
            
            metrics = {
                'files_completed': len([p for p in self._file_progress.values() if p >= 100]),
                'total_files': self._total_files,
                'paragraphs_processed': self._paragraphs_processed,
                'total_paragraphs': self._total_paragraphs,
                'processing_speed': self._processing_speed,
                'features_extracted': self._features_extracted,
                'elapsed_time': elapsed,
                'current_stage': self._processing_stage,
                'current_file': self._current_file_name,
                'overall_progress': self._overall_progress,
                'current_message': self._current_message
            }
            
            # Calculate rates and estimates
            if elapsed > 0:
                # ðŸš€ ENHANCEMENT: Better speed calculations
                files_completed = metrics['files_completed']
                para_processed = self._paragraphs_processed
                
                metrics.update({
                    'files_per_second': files_completed / elapsed,
                    'paragraphs_per_second': para_processed / elapsed,
                    'estimated_total_time': (elapsed * 100) / max(self._overall_progress, 1),
                    'estimated_remaining': max(0, ((elapsed * 100) / max(self._overall_progress, 1)) - elapsed)
                })
            else:
                metrics.update({
                    'files_per_second': 0,
                    'paragraphs_per_second': 0,
                    'estimated_total_time': 0,
                    'estimated_remaining': 0
                })
        
        return metrics
    
    def get_file_progress_detailed(self, file_name: str) -> Dict[str, Any]:
        """
        Get detailed progress information for a specific file.
        
        Args:
            file_name: Name of the file
            
        Returns:
            Dict containing detailed progress info
        """
        with self._lock:
            if file_name not in self._file_progress:
                return {}
            
            total_paragraphs = self._file_paragraph_counts.get(file_name, 0)
            processed_paragraphs = self._file_paragraph_progress.get(file_name, 0)
            file_percentage = self._file_progress.get(file_name, 0)
            
            return {
                'percentage': file_percentage,
                'total_paragraphs': total_paragraphs,
                'paragraph_progress': processed_paragraphs,
                'paragraphs_remaining': max(0, total_paragraphs - processed_paragraphs),
                'is_complete': file_percentage >= 100,
                'processing_rate': processed_paragraphs / self.elapsed_time if self.elapsed_time > 0 else 0
            }
    
    def _format_duration(self, seconds: float) -> str:
        """Format duration in human-readable format."""
        if seconds < 60:
            return f"{seconds:.1f}s"
        elif seconds < 3600:
            minutes = int(seconds // 60)
            secs = seconds % 60
            return f"{minutes}m {secs:.1f}s"
        else:
            hours = int(seconds // 3600)
            minutes = int((seconds % 3600) // 60)
            secs = seconds % 60
            return f"{hours}h {minutes}m {secs:.1f}s"
    
    def _notify_callbacks(self, message: str):
        """ðŸš€ FIXED: Notify all registered callbacks of progress update with thread safety."""
        current_time = time.time()
        
        with self._lock:
            update = ProgressUpdate(
                current=self._current_file,
                total=self._total_files,
                percentage=self._overall_progress,
                message=message,
                timestamp=current_time,
                status=self._status,
                details={
                    'file_progress': self._file_progress.copy(),
                    'file_paragraph_counts': self._file_paragraph_counts.copy(),
                    'file_paragraph_progress': self._file_paragraph_progress.copy(),
                    'error_message': self._error_message,
                    'start_time': self._start_time,
                    'end_time': self._end_time,
                    'real_time_metrics': self.get_real_time_metrics(),
                    'processing_stage': self._processing_stage,
                    'current_file_name': self._current_file_name,
                    'performance_metrics': self._performance_metrics.copy()
                }
            )
            
            callbacks_copy = self._callbacks.copy()
        
        # Call callbacks outside of lock to prevent deadlocks
        for callback in callbacks_copy:
            try:
                callback(update)
            except Exception as e:
                logger.error(f"Error in progress callback: {e}")
    
    @property
    def is_processing(self) -> bool:
        """Check if currently processing."""
        with self._lock:
            return self._status in [ProcessingStatus.STARTING, ProcessingStatus.PROCESSING]
    
    @property
    def is_completed(self) -> bool:
        """Check if processing is completed."""
        with self._lock:
            return self._status == ProcessingStatus.COMPLETED
    
    @property
    def is_error(self) -> bool:
        """Check if there was an error."""
        with self._lock:
            return self._status == ProcessingStatus.ERROR
    
    @property
    def is_cancelled(self) -> bool:
        """Check if processing was cancelled."""
        with self._lock:
            return self._status == ProcessingStatus.CANCELLED
    
    @property
    def overall_progress(self) -> float:
        """Get overall progress percentage."""
        with self._lock:
            return self._overall_progress
    
    @property
    def current_message(self) -> str:
        """Get current status message."""
        with self._lock:
            return self._current_message
    
    @property
    def status(self) -> ProcessingStatus:
        """Get current processing status."""
        with self._lock:
            return self._status
    
    @property
    def elapsed_time(self) -> float:
        """Get elapsed processing time."""
        with self._lock:
            if self._start_time is None:
                return 0.0
            
            end_time = self._end_time or time.time()
            return end_time - self._start_time
    
    @property
    def estimated_time_remaining(self) -> float:
        """ðŸš€ FIXED: Estimate remaining processing time with better calculation."""
        with self._lock:
            if not self.is_processing or self._overall_progress <= 0:
                return 0.0
            
            elapsed = self.elapsed_time
            progress_ratio = self._overall_progress / 100.0
            
            if progress_ratio > 0:
                total_estimated = elapsed / progress_ratio
                return max(0, total_estimated - elapsed)
        
        return 0.0
    
    def get_file_progress(self, file_name: str) -> float:
        """Get progress for a specific file."""
        with self._lock:
            return self._file_progress.get(file_name, 0.0)
    
    def get_total_paragraphs_processed(self) -> int:
        """Get total number of paragraphs processed across all files."""
        with self._lock:
            return sum(self._file_paragraph_progress.values())
    
    def get_total_paragraphs_count(self) -> int:
        """Get total number of paragraphs across all files."""
        with self._lock:
            return sum(self._file_paragraph_counts.values())
    
    def get_enhanced_statistics(self) -> Dict[str, Any]:
        """ðŸš€ FIXED: Get comprehensive processing statistics with enhanced metrics."""
        with self._lock:
            base_stats = {
                'total_files': self._total_files,
                'current_file': self._current_file + 1 if self.is_processing else self._current_file,
                'overall_progress': self._overall_progress,
                'status': self._status.value,
                'elapsed_time': self.elapsed_time,
                'estimated_remaining': self.estimated_time_remaining,
                'completed_files': len([p for p in self._file_progress.values() if p >= 100]),
                'total_paragraphs_processed': self.get_total_paragraphs_processed(),
                'total_paragraphs_count': self.get_total_paragraphs_count(),
                'error_message': self._error_message
            }
            
            # Add enhanced metrics
            if self.elapsed_time > 0:
                base_stats.update({
                    'files_per_second': base_stats['completed_files'] / self.elapsed_time,
                    'paragraphs_per_second': self.get_total_paragraphs_processed() / self.elapsed_time,
                    'features_extracted': self._features_extracted,
                    'processing_efficiency': min(100, (self.get_total_paragraphs_processed() / max(1, self.elapsed_time)) * 10),
                    'current_stage': self._processing_stage,
                    'current_file_name': self._current_file_name,
                    'performance_breakdown': self._performance_metrics.copy()
                })
        
        return base_stats


# Backward compatibility - alias to new class
ProgressTracker = EnhancedProgressTracker


class EnhancedProgressReporter:
    """ðŸš€ FIXED: Enhanced progress reporter for console output with detailed metrics."""
    
    def __init__(self, tracker: EnhancedProgressTracker):
        self.tracker = tracker
        self.tracker.add_callback(self._on_progress_update)
        self.last_percentage = -1
        self.last_report_time = 0
        
    def _on_progress_update(self, update: ProgressUpdate):
        """ðŸš€ FIXED: Handle progress updates with enhanced detail and smooth reporting."""
        current_time = time.time()
        
        # ðŸš€ CRITICAL FIX: More frequent console updates for better feedback
        should_print = (
            int(update.percentage) % 2 == 0 and int(update.percentage) != self.last_percentage  # Every 2% instead of 5%
        ) or (current_time - self.last_report_time > 5)  # Every 5 seconds instead of 10
        
        if should_print:
            metrics = self.tracker.get_real_time_metrics()
            
            message = (f"ðŸš€ FIXED Progress: {update.percentage:.1f}% | "
                      f"Files: {metrics['files_completed']}/{metrics['total_files']} | "
                      f"Paragraphs: {metrics['paragraphs_processed']}")
            
            if metrics.get('paragraphs_per_second', 0) > 0:
                message += f" ({metrics['paragraphs_per_second']:.1f} para/sec)"
            
            if metrics.get('estimated_remaining', 0) > 0:
                remaining_formatted = self.tracker._format_duration(metrics['estimated_remaining'])
                message += f" | ETA: {remaining_formatted}"
            
            print(message)
            self.last_percentage = int(update.percentage)
            self.last_report_time = current_time
        
        # Always print completion, errors, and important stage changes
        if update.status in [ProcessingStatus.COMPLETED, ProcessingStatus.ERROR, ProcessingStatus.CANCELLED]:
            print(f"Status: {update.message}")
        elif ("spaCy processing" in update.message or 
              "Feature extraction" in update.message or 
              "ðŸ“‚" in update.message or "ðŸ§ " in update.message or "âš¡" in update.message):
            print(f"Stage: {update.message}")
    
    def cleanup(self):
        """Remove callback from tracker."""
        self.tracker.remove_callback(self._on_progress_update)


# Backward compatibility - alias to old class name
SimpleProgressReporter = EnhancedProgressReporter


class ProgressUpdateQueue:
    """ðŸš€ NEW: Thread-safe queue for progress updates to prevent GUI blocking."""
    
    def __init__(self, max_size: int = 100):
        self.queue = []
        self.max_size = max_size
        self._lock = threading.Lock()
    
    def add_update(self, update: ProgressUpdate):
        """Add an update to the queue."""
        with self._lock:
            self.queue.append(update)
            
            # Keep queue size manageable
            if len(self.queue) > self.max_size:
                self.queue.pop(0)
    
    def get_latest_updates(self, count: int = 10) -> list:
        """Get the latest updates from the queue."""
        with self._lock:
            return self.queue[-count:] if self.queue else []
    
    def clear(self):
        """Clear all updates from the queue."""
        with self._lock:
            self.queue.clear()


def create_progress_callback_wrapper(gui_callback: Callable) -> Callable:
    """
    ðŸš€ NEW: Create a thread-safe wrapper for GUI progress callbacks.
    
    Args:
        gui_callback: The GUI callback function
        
    Returns:
        Callable: Thread-safe wrapper function
    """
    def wrapped_callback(percentage: int, total: int, message: str):
        try:
            # Ensure we're calling the GUI callback in a thread-safe manner
            gui_callback(percentage, total, message)
        except Exception as e:
            logger.error(f"Error in progress callback wrapper: {e}")
    
    return wrapped_callback
